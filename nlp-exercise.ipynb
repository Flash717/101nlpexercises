{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 101 NLP Exercises\n",
    "\n",
    "see also on (the website)[https://machinelearningplus.com/nlp/nlp-exercises/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/florianknaus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Error loading stop: Package 'stop' not found in index\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/florianknaus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stop')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x156128ca0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last\n",
      "week\n",
      ",\n",
      "the\n",
      "University\n",
      "of\n",
      "Cambridge\n",
      "in\n",
      "England\n",
      "shared\n",
      "its\n",
      "own\n",
      "research\n",
      "that\n",
      "shows\n",
      "if\n",
      "everyone\n",
      "wears\n",
      "a\n",
      "mask\n",
      "outside\n",
      "home\n",
      ",\n",
      "dreaded\n",
      "'\n",
      "second\n",
      "wave\n",
      "'\n",
      "of\n",
      "the\n",
      "pandemic\n",
      "can\n",
      "be\n",
      "avoided\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "text = \"Last week, the University of Cambridge in England shared its own research that shows if everyone wears a mask outside home, dreaded 'second wave' of the pandemic can be avoided.\"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outbreak of the coronavirus disease 2019 (COVID-19) has created a global health crisis that has had a deep impact on the way we perceive our world and our everyday lives.\n",
      "Not only the rate of contagion and patterns of transmission threatens our sense of agency, but the safety measures put in place to contain the spread of the virus also require social distancing by refraining from doing what is inherently human, which is to find solace in the company of others.\n",
      "Within this context of physical threat, social and physical distancing, as well as public alarm, what has been (and can be) the role of the different mass media channels in our lives on individual, social and societal levels?\n",
      "Mass media have long been recognized as powerful forces shaping how we experience the world and ourselves.\n",
      "This recognition is accompanied by a growing volume of research, that closely follows the footsteps of technological transformations (e.g. radio, movies, television, the internet, mobiles) and the zeitgeist (e.g. cold war, 9/11, climate change) in an attempt to map mass media major impacts on how we perceive ourselves, both as individuals and citizens.\n",
      "Are media (broadcast and digital) still able to convey a sense of unity reaching large audiences, or are messages lost in the noisy crowd of mass self-communication?\n"
     ]
    }
   ],
   "source": [
    "text=\"\"\"The outbreak of the coronavirus disease 2019 (COVID-19) has created a global health crisis that has had a deep impact on the way we perceive our world and our everyday lives. Not only the rate of contagion and patterns of transmission threatens our sense of agency, but the safety measures put in place to contain the spread of the virus also require social distancing by refraining from doing what is inherently human, which is to find solace in the company of others. Within this context of physical threat, social and physical distancing, as well as public alarm, what has been (and can be) the role of the different mass media channels in our lives on individual, social and societal levels? Mass media have long been recognized as powerful forces shaping how we experience the world and ourselves. This recognition is accompanied by a growing volume of research, that closely follows the footsteps of technological transformations (e.g. radio, movies, television, the internet, mobiles) and the zeitgeist (e.g. cold war, 9/11, climate change) in an attempt to map mass media major impacts on how we perceive ourselves, both as individuals and citizens. Are media (broadcast and digital) still able to convey a sense of unity reaching large audiences, or are messages lost in the noisy crowd of mass self-communication? \"\"\"\n",
    "doc = nlp(text)\n",
    "for sentence in doc.sents:\n",
    "    print(sentence.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1045, 2293, 3500, 2161, 1012, 1045, 2175, 13039, 2007, 2026, 2814, 102]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] i love spring season. i go hiking with my friends [SEP]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "text=\"I love spring season. I go hiking with my friends\"\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "encoded_input = tokenizer.encode(text)\n",
    "print(encoded_input)\n",
    "tokenizer.decode(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1045, 2293, 3500, 2161, 1012, 1045, 2175, 13039, 2007, 2026, 2814, 102]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] i love spring season. i go hiking with my friends [SEP]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "inputs = tokenizer.encode(text)\n",
    "print(inputs)\n",
    "tokenizer.decode(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Walter', 'feeling anxious', 'He', 'diagnosed today', 'He probably', 'best person I know']\n"
     ]
    }
   ],
   "source": [
    "text = \"Walter was feeling anxious. He was diagnosed today. He probably is the best person I know.\"\n",
    "stoplist = [\"is\", \"the\", \"was\", \".\", \",\", \"-\", \"!\", \"?\"]\n",
    "for i in stoplist:\n",
    "    text = text.replace(i, \"DELIM\")\n",
    "words = [t.strip() for t in text.split(\"DELIM\") if t]\n",
    "words_filtered = list(filter(lambda a: a not in [''], words))\n",
    "print(words_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outbreak of coronavirus disease 2019 ( COVID-19 ) created global health crisis that had deep impact on way we perceive our world and our everyday lives Not only rate of contagion and patterns of transmission threatens our sense of agency but safety measures put in place to contain spread of virus also require social distancing by refraining from doing what inherently human which to find solace in company of others Within this context of physical threat social and physical distancing as well as public alarm what been ( and can be ) role of different mass media channels in our lives on individual social and societal levels Mass media have long been recognized as powerful forces shaping how we experience world and ourselves This recognition accompanied by growing volume of research that closely follows footsteps of technological transformations ( e.g. radio movies television internet mobiles ) and zeitgeist ( e.g. cold war 9/11 climate change ) in an attempt to map mass media major impacts on how we perceive ourselves both as individuals and citizens Are media ( broadcast and digital ) still able to convey sense of unity reaching large audiences or are messages lost in noisy crowd of mass self communication \n"
     ]
    }
   ],
   "source": [
    "text=\"\"\"the outbreak of coronavirus disease 2019 (COVID-19) has created a global health crisis that has had a deep impact on the way we perceive our world and our everyday lives. Not only the rate of contagion and patterns of transmission threatens our sense of agency, but the safety measures put in place to contain the spread of the virus also require social distancing by refraining from doing what is inherently human, which is to find solace in the company of others. Within this context of physical threat, social and physical distancing, as well as public alarm, what has been (and can be) the role of the different mass media channels in our lives on individual, social and societal levels? Mass media have long been recognized as powerful forces shaping how we experience the world and ourselves. This recognition is accompanied by a growing volume of research, that closely follows the footsteps of technological transformations (e.g. radio, movies, television, the internet, mobiles) and the zeitgeist (e.g. cold war, 9/11, climate change) in an attempt to map mass media major impacts on how we perceive ourselves, both as individuals and citizens. Are media (broadcast and digital) still able to convey a sense of unity reaching large audiences, or are messages lost in the noisy crowd of mass self-communication? \"\"\"\n",
    "stoplist = [\"is\", \"the\", \"was\", \"has\", \"a\", \".\", \",\", \"-\", \"!\", \"?\"]\n",
    "doc = nlp(text)\n",
    "result = \"\"\n",
    "for i in doc:\n",
    "    if i.text not in stoplist:\n",
    "        result += i.text + \" \"\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outbreak coronavirus disease 2019 ( COVID-19 ) created global health crisis deep impact way perceive world everyday lives . Not rate contagion patterns transmission threatens sense agency , safety measures put place contain spread virus also require social distancing refraining inherently human , find solace company others . Within context physical threat , social physical distancing , well public alarm , ( ) role different mass media channels lives individual , social societal levels ? Mass media long recognized powerful forces shaping experience world . This recognition accompanied growing volume research , closely follows footsteps technological transformations ( e.g . radio , movies , television , internet , mobiles ) zeitgeist ( e.g . cold war , 9/11 , climate change ) attempt map mass media major impacts perceive , individuals citizens . Are media ( broadcast digital ) still able convey sense unity reaching large audiences , messages lost noisy crowd mass self-communication ?\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "stoplist = stopwords.words('english')\n",
    "result = []\n",
    "all_tokens = nltk.word_tokenize(text)\n",
    "for i in all_tokens:\n",
    "    if i not in stoplist:\n",
    "        result.append(i)\n",
    "print(\" \".join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Jonas great guy Adam evil Martha fool\n"
     ]
    }
   ],
   "source": [
    "text=\" Jonas was a JUNK great guy NIL Adam was evil NIL Martha JUNK was more of a fool \"\n",
    "stoplist = [\"JUNK\", \"NIL\"]\n",
    "for w in stoplist:\n",
    "    nlp.vocab[w].is_stop = True\n",
    "doc = nlp(text)\n",
    "tokens = [token.text for token in doc if not token.is_stop]\n",
    "print(\" \".join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The match has concluded India has won the match Will we fin the finals too\n"
     ]
    }
   ],
   "source": [
    "text=\"The match has concluded !!! India has won the match . Will we fin the finals too ? !\"\n",
    "doc = nlp(text)\n",
    "tokens = [token.text for token in doc if not token.is_punct]\n",
    "print(\" \".join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danc is an art . student should be taught danc as a subject in school . i danc in mani of my school function . some peopl are alway hesit to danc .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "text= \"Dancing is an art. Students should be taught dance as a subject in schools . I danced in many of my school function. Some people are always hesitating to dance.\"\n",
    "stemmer = PorterStemmer()\n",
    "result = []\n",
    "for token in nltk.word_tokenize(text):\n",
    "    result.append(stemmer.stem(token))\n",
    "\n",
    "print(\" \".join(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input:\n",
    "\n",
    "text= \"Dancing is an art. Students should be taught dance as a subject in schools . I danced in many of my school function. Some people are always hesitating to dance.\"\n",
    "\n",
    "Desired Output:\n",
    "\n",
    "text= 'dancing be an art . student should be teach dance as a subject in school . -PRON- dance in many of -PRON- school function . some people be always hesitate to dance .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dancing be an art . student should be teach dance as a subject in school . I dance in many of my school function . some people be always hesitate to dance .\n"
     ]
    }
   ],
   "source": [
    "text= \"Dancing is an art. Students should be taught dance as a subject in schools . I danced in many of my school function. Some people are always hesitating to dance.\"\n",
    "doc = nlp(text)\n",
    "result = [token.lemma_ for token in doc]\n",
    "print(\" \".join(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. How to extract usernames from emails ?\n",
    "Difficulty Level : L2\n",
    "\n",
    "Q. Extract the usernames from the email addresses present in the text\n",
    "\n",
    "Input :\n",
    "\n",
    "text= \"The new registrations are potter709@gmail.com , elixir101@gmail.com. If you find any disruptions, kindly contact granger111@gamil.com or severus77@gamil.com \"\n",
    "Desired Output :\n",
    "\n",
    "['potter709', 'elixir101', 'granger111', 'severus77']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['potter709', 'elixir101', 'granger111', 'severus77']\n"
     ]
    }
   ],
   "source": [
    "text= \"The new registrations are potter709@gmail.com , elixir101@gmail.com. If you find any disruptions, kindly contact granger111@gamil.com or severus77@gamil.com \"\n",
    "doc = nlp(text)\n",
    "emails = [token.text for token in doc if token.like_email]\n",
    "output = [email[:email.index('@')] for email in emails]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. How to find the most common words in the text excluding stopwords\n",
    "Difficulty Level : L2\n",
    "\n",
    "Q. Extract the top 10 most common words in the given text excluding stopwords.\n",
    "\n",
    "Input :\n",
    "\n",
    "text=\"\"\"Junkfood - Food that do no good to our body. And there's no need of them in our body but still we willingly eat them because they are great in taste and easy to cook or ready to eat. Junk foods have no or very less nutritional value and irrespective of the way they are marketed, they are not healthy to consume.The only reason of their gaining popularity and increased trend of consumption is \n",
    "that they are ready to eat or easy to cook foods. People, of all age groups are moving towards Junkfood as it is hassle free and often ready to grab and eat. Cold drinks, chips, noodles, pizza, burgers, French fries etc. are few examples from the great variety of junk food available in the market.\n",
    " Junkfood is the most dangerous food ever but it is pleasure in eating and it gives a great taste in mouth examples of Junkfood are kurkure and chips.. cold rings are also source of junk food... they shud nt be ate in high amounts as it results fatal to our body... it cn be eated in a limited extend ... in research its found tht ths junk foods r very dangerous fr our health\n",
    "Junkfood is very harmful that is slowly eating away the health of the present generation. The term itself denotes how dangerous it is for our bodies. Most importantly, it tastes so good that people consume it on a daily basis. However, not much awareness is spread about the harmful effects of Junkfood .\n",
    "The problem is more serious than you think. Various studies show that Junkfood impacts our health negatively. They contain higher levels of calories, fats, and sugar. On the contrary, they have very low amounts of healthy nutrients and lack dietary fibers. Parents must discourage their children from consuming junk food because of the ill effects it has on one’s health.\n",
    "Junkfood is the easiest way to gain unhealthy weight. The amount of fats and sugar in the food makes you gain weight rapidly. However, this is not a healthy weight. It is more of fats and cholesterol which will have a harmful impact on your health. Junk food is also one of the main reasons for the increase in obesity nowadays.\n",
    "This food only looks and tastes good, other than that, it has no positive points. The amount of calorie your body requires to stay fit is not fulfilled by this food. For instance, foods like French fries, burgers, candy, and cookies, all have high amounts of sugar and fats. Therefore, this can result in long-term illnesses like diabetes and high blood pressure. This may also result in kidney failure.\"\"\"\n",
    "\n",
    "Desired Output:\n",
    "\n",
    "text= {Junkfood: 10,\n",
    " food: 8,\n",
    " good: 5,\n",
    " harmful : 3\n",
    " body: 1,\n",
    " need: 1,\n",
    "\n",
    " ...(truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Junkfood', 8), ('food', 8), ('health', 5), ('body', 4), ('eat', 4), ('foods', 4), ('junk', 4), ('The', 4), ('fats', 4), ('good', 3)]\n"
     ]
    }
   ],
   "source": [
    "text=\"\"\"Junkfood - Food that do no good to our body. And there's no need of them in our body but still we willingly eat them because they are great in taste and easy to cook or ready to eat. Junk foods have no or very less nutritional value and irrespective of the way they are marketed, they are not healthy to consume.The only reason of their gaining popularity and increased trend of consumption is \n",
    "that they are ready to eat or easy to cook foods. People, of all age groups are moving towards Junkfood as it is hassle free and often ready to grab and eat. Cold drinks, chips, noodles, pizza, burgers, French fries etc. are few examples from the great variety of junk food available in the market.\n",
    " Junkfood is the most dangerous food ever but it is pleasure in eating and it gives a great taste in mouth examples of Junkfood are kurkure and chips.. cold rings are also source of junk food... they shud nt be ate in high amounts as it results fatal to our body... it cn be eated in a limited extend ... in research its found tht ths junk foods r very dangerous fr our health\n",
    "Junkfood is very harmful that is slowly eating away the health of the present generation. The term itself denotes how dangerous it is for our bodies. Most importantly, it tastes so good that people consume it on a daily basis. However, not much awareness is spread about the harmful effects of Junkfood .\n",
    "The problem is more serious than you think. Various studies show that Junkfood impacts our health negatively. They contain higher levels of calories, fats, and sugar. On the contrary, they have very low amounts of healthy nutrients and lack dietary fibers. Parents must discourage their children from consuming junk food because of the ill effects it has on one’s health.\n",
    "Junkfood is the easiest way to gain unhealthy weight. The amount of fats and sugar in the food makes you gain weight rapidly. However, this is not a healthy weight. It is more of fats and cholesterol which will have a harmful impact on your health. Junk food is also one of the main reasons for the increase in obesity nowadays.\n",
    "This food only looks and tastes good, other than that, it has no positive points. The amount of calorie your body requires to stay fit is not fulfilled by this food. For instance, foods like French fries, burgers, candy, and cookies, all have high amounts of sugar and fats. Therefore, this can result in long-term illnesses like diabetes and high blood pressure. This may also result in kidney failure.\"\"\"\n",
    "tokens = nltk.word_tokenize(text)\n",
    "filtered_tokens = [token for token in tokens if (not token in nltk.corpus.stopwords.words('english') and token.isalnum())]\n",
    "counts = nltk.FreqDist(filtered_tokens)\n",
    "print(counts.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. How to do spell correction in a given text ?\n",
    "Difficulty Level : L2\n",
    "\n",
    "Q. Correct the spelling errors in the following text\n",
    "\n",
    "Input :\n",
    "\n",
    "text=\"He is a gret person. He beleives in bod\"\n",
    "Desired Output:\n",
    "\n",
    "text=\"He is a great person. He believes in god\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He is a great person. He believes in god\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text=\"He is a gret person. He beleives in bod\"\n",
    "text = TextBlob(text)\n",
    "print(text.correct())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. How to tokenize tweets ?\n",
    "Difficulty Level : L2\n",
    "\n",
    "Q. Clean the following tweet and tokenize them\n",
    "\n",
    "Input :\n",
    "\n",
    "text=\" Having lots of fun #goa #vaction #summervacation. Fancy dinner @Beachbay restro :) \"\n",
    "Desired Output :\n",
    "\n",
    "['Having',\n",
    " 'lots',\n",
    " 'of',\n",
    " 'fun',\n",
    " 'goa',\n",
    " 'vaction',\n",
    " 'summervacation',\n",
    " 'Fancy',\n",
    " 'dinner',\n",
    " 'Beachbay',\n",
    " 'restro']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Having', 'lots', 'of', 'fun', '#goa', '#vaction', '#summervacation', '.', 'Fancy', 'dinner', '@Beachbay', 'restro', ':)']\n"
     ]
    }
   ],
   "source": [
    "text=\" Having lots of fun #goa #vaction #summervacation. Fancy dinner @Beachbay restro :) \"\n",
    "import re\n",
    "text = re.sub(r'[^\\w]', ' ', text)\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. How to extract all the nouns in a text?\n",
    "Difficulty Level : L2\n",
    "\n",
    "Q. Extract and print all the nouns present in the below text\n",
    "\n",
    "Input:\n",
    "\n",
    "text=\"James works at Microsoft. She lives in manchester and likes to play the flute\"\n",
    "Desired Output :\n",
    "\n",
    "James\n",
    "Microsoft\n",
    "manchester\n",
    "flute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James\n",
      "Microsoft\n",
      "manchester\n",
      "flute\n"
     ]
    }
   ],
   "source": [
    "text=\"James works at Microsoft. She lives in manchester and likes to play the flute\"\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    if token.pos_ == \"PROPN\" or token.pos_ == \"NOUN\":\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. How to extract all the pronouns in a text?\n",
    "Difficulty Level : L2\n",
    "\n",
    "Q. Extract and print all the pronouns in the text\n",
    "\n",
    "Input :\n",
    "text=\"John is happy finally. He had landed his dream job finally. He told his mom. She was elated \"\n",
    "\n",
    "Desired Output :\n",
    " He\n",
    " He\n",
    " She"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He\n",
      "his\n",
      "He\n",
      "his\n",
      "She\n"
     ]
    }
   ],
   "source": [
    "text=\"John is happy finally. He had landed his dream job finally. He told his mom. She was elated \"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    if token.pos_ == \"PRON\":\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. How to find similarity between two words?\n",
    "Find the similarity between any two words.\n",
    "\n",
    "Input :\n",
    "word1=\"amazing\"\n",
    "word2=\"terrible\"\n",
    "word3=\"excellent\"\n",
    "\n",
    "Desired Output:\n",
    "#> similarity between amazing and terrible is 0.46189071343764604\n",
    "#> similarity between amazing and excellent is 0.638820708673777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3152.07s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n",
      "0.46189069747924805\n",
      "0.6388207674026489\n"
     ]
    }
   ],
   "source": [
    "word1=\"amazing\"\n",
    "word2=\"terrible\"\n",
    "word3=\"excellent\"\n",
    "\n",
    "import spacy\n",
    "!python -m spacy download en_core_web_lg\n",
    "nlp=spacy.load('en_core_web_lg')\n",
    "token1=nlp(word1)\n",
    "token2=nlp(word2)\n",
    "token3=nlp(word3)\n",
    "\n",
    "print(token1.similarity(token2))\n",
    "print(token1.similarity(token3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. How to find similarity between two documents?\n",
    "Difficulty Level : L2\n",
    "\n",
    "Q. Find the similarity between any two text documents\n",
    "\n",
    "Input :\n",
    "text1=\"John lives in Canada\"\n",
    "text2=\"James lives in America, though he's not from there\"\n",
    "\n",
    "Desired Output :\n",
    " 0.792817083631068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7928170561790466"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1=\"John lives in Canada\"\n",
    "text2=\"James lives in America, though he's not from there\"\n",
    "\n",
    "doc1=nlp(text1)\n",
    "doc2=nlp(text2)\n",
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. How to find the cosine similarity of two documents?\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Find the cosine similarity between two given documents\n",
    "\n",
    "Input\n",
    "text1='Taj Mahal is a tourist place in India'\n",
    "text2='Great Wall of China is a tourist place in china'\n",
    "\n",
    "Desired Output :\n",
    "[[1.         0.45584231]\n",
    " [0.45584231 1.        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.45584231]\n",
      " [0.45584231 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "text1='Taj Mahal is a tourist place in India'\n",
    "text2='Great Wall of China is a tourist place in china'\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Create the Document Term Matrix\n",
    "tfidf_vectorizer = CountVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([text1, text2])\n",
    "\n",
    "# Compute the cosine similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "print(cosine_sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-exercise-WwCX1lUo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
